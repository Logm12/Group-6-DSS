# File: htdocs/DSS/python_algorithm/utils.py
import json
from datetime import datetime, time as dt_time, date, timedelta
import traceback
from typing import List, Dict, Tuple, Any, Set, Optional
from collections import defaultdict
from dataclasses import dataclass, field

try:
    # Assuming models.py is updated as per your provided code
    from models import Course, Instructor, Classroom, TimeSlot, Student
    MODELS_IMPORTED_SUCCESSFULLY = True
    print("UTILS.PY: Successfully imported models from models.py")
except ImportError:
    print("UTILS.PY: Could not import from models.py. Using placeholder classes for testing utils.py.")
    MODELS_IMPORTED_SUCCESSFULLY = False
    # Placeholder definitions (updated to reflect string times/dates in TimeSlot)
    @dataclass
    class Course: # As per your new models.py
        id: str
        name: str
        num_students: int
        required_periods_per_session: int
        assigned_instructor_id: str

    @dataclass
    class Instructor: # As per your new models.py
        id: str
        name: str
        unavailable_slot_ids: Set[str] = field(default_factory=set)

    @dataclass
    class Classroom: # As per your new models.py
        id: int
        room_code: str
        capacity: int
        type: Optional[str] = None

    @dataclass
    class TimeSlot: # As per your new models.py
        id: str
        day_of_week: str
        session_date: str  # YYYY-MM-DD string
        start_time: str    # HH:MM:SS string
        end_time: str      # HH:MM:SS string
        num_periods: int

    @dataclass
    class Student: # As per your new models.py
        id: str
        enrolled_course_ids: Set[str] = field(default_factory=set)

def parse_time(t_str: Any) -> Optional[dt_time]: # This function is still useful if converting strings to time objects elsewhere
    if isinstance(t_str, dt_time): return t_str
    if isinstance(t_str, timedelta): return (datetime.min + t_str).time()
    if not isinstance(t_str, str): return None
    try: return datetime.strptime(t_str, '%H:%M:%S').time()
    except ValueError:
        try: return datetime.strptime(t_str, '%H:%M').time()
        except ValueError: return None

DEFAULT_SETTINGS = {
    "basic_slot_duration_minutes": 50,
    "break_duration_minutes": 5,
    "lecturer_min_break_minutes": 10,
    "student_max_consecutive_slots": 6,
    "target_classroom_fill_ratio_min": 0.5,
    "target_classroom_fill_ratio_max": 1.0,
    "lecturer_min_teaching_periods_per_semester": 10,
    "lecturer_max_teaching_periods_per_semester": 40,
    "penalty_student_clash_base": 100,
    "penalty_lecturer_overload_base": 50,
    "penalty_lecturer_underload_base": 30,
    "penalty_lecturer_insufficient_break_base": 40,
    "penalty_classroom_underutilized_base": 10,
    "penalty_classroom_slightly_empty_base": 2,
}

def check_time_overlap(slot_start_str: Optional[str], slot_end_str: Optional[str],
                       busy_start_str: Optional[str], busy_end_str: Optional[str]) -> bool:
    # Convert string times to datetime.time objects for comparison
    slot_start = parse_time(slot_start_str)
    slot_end = parse_time(slot_end_str)
    busy_start = parse_time(busy_start_str)
    busy_end = parse_time(busy_end_str)

    if not all(isinstance(t, dt_time) for t in [slot_start, slot_end, busy_start, busy_end]):
        # print(f"DEBUG check_time_overlap: Invalid time object after parsing. slot_start: {slot_start}, slot_end: {slot_end}, busy_start: {busy_start}, busy_end: {busy_end}")
        return False
    if slot_end <= slot_start or busy_end <= busy_start:
        # print(f"DEBUG check_time_overlap: Invalid time range. slot_start: {slot_start}, slot_end: {slot_end}, busy_start: {busy_start}, busy_end: {busy_end}")
        return False
    return max(slot_start, busy_start) < min(slot_end, busy_end)

def save_output_data_to_json(data: Any, filepath: str):
    print(f"UTILS: Attempting to save data to {filepath}")
    try:
        def convert_special_types(obj):
            if isinstance(obj, set): return list(obj)
            # date, datetime, dt_time objects are less likely now with string models, but keep for safety
            if isinstance(obj, (date, datetime, dt_time)): return obj.isoformat()
            if isinstance(obj, timedelta):
                 total_seconds = int(obj.total_seconds())
                 hours, remainder = divmod(total_seconds, 3600)
                 minutes, seconds = divmod(remainder, 60)
                 return f"{hours:02}:{minutes:02}:{seconds:02}"
            if hasattr(type(obj), '__dataclass_fields__'):
                return obj.__dict__
            if hasattr(obj, '__dict__') and not callable(obj.__dict__):
                 return obj.__dict__
            raise TypeError(f"Object of type {obj.__class__.__name__} is not JSON serializable")

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False, default=convert_special_types)
        print(f"UTILS: Successfully saved data to {filepath}")
    except TypeError as te:
        print(f"UTILS: TypeError saving to {filepath}. Error: {te}")
        problematic_obj = None
        if isinstance(data, dict):
            for k, v in data.items():
                try: json.dumps({k: v}, default=convert_special_types)
                except TypeError:
                    print(f"  Problematic Key: '{k}', Type: {type(v)}, Value (partial): {str(v)[:100]}")
                    problematic_obj = v
                    break
        elif isinstance(data, list) and data:
             try: json.dumps(data[0], default=convert_special_types)
             except TypeError:
                 print(f"  Problematic List item 0 Type: {type(data[0])}, Value (partial): {str(data[0])[:100]}")
                 problematic_obj = data[0]

        if problematic_obj and hasattr(type(problematic_obj), '__dataclass_fields__'):
            print(f"  Problematic object is a dataclass. Fields: {problematic_obj.__dict__}")
            for field_name, field_value in problematic_obj.__dict__.items():
                try:
                    json.dumps({field_name: field_value}, default=convert_special_types)
                except TypeError:
                    print(f"    Unserializable field: '{field_name}', Type: {type(field_value)}")
    except Exception as e:
        print(f"UTILS: Error saving data to {filepath}: {e}")
        traceback.print_exc()


def preprocess_data_for_cp_and_ga(
    courses_model_list: List[Course],
    instructors_model_list: List[Instructor],
    classrooms_model_list: List[Classroom],
    timeslots_model_list: List[TimeSlot],
    students_model_list: List[Student],
    semester_id_for_settings: Optional[int] = None,
    priority_settings: Optional[Dict[str, str]] = None
) -> Dict[str, Any]:
    processed_data = {
        "settings": DEFAULT_SETTINGS.copy(),
        "courses": {}, "lecturers": {}, "classrooms": {}, "timeslots": {},
        "mappings": {
            "lecturer_str_id_to_int_map": {}, "lecturer_int_map_to_str_id": {},
            "timeslot_str_id_to_int_map": {}, "timeslot_int_map_to_str_id": {},
            "classroom_pk_to_int_map": {}, "classroom_int_map_to_pk": {},
        },
        "student_enrollments_map": defaultdict(set),
        "students_courses_map": defaultdict(set)
    }

    if semester_id_for_settings is not None:
        processed_data["settings"]["current_semester_id"] = semester_id_for_settings
    
    print("UTILS: Starting preprocessing for CP/GA modules...")

    if priority_settings:
        priority_multipliers = {"low": 0.5, "medium": 1.0, "high": 2.0}
        # ... (priority settings logic remains the same) ...
        student_prio = priority_settings.get("student_clash", "medium")
        processed_data["settings"]["penalty_student_clash"] = \
            DEFAULT_SETTINGS.get("penalty_student_clash_base", 100) * priority_multipliers.get(student_prio, 1.0)

        lecturer_prio = priority_settings.get("lecturer_load_break", "medium")
        multiplier_lect = priority_multipliers.get(lecturer_prio, 1.0)
        processed_data["settings"]["penalty_lecturer_overload"] = \
            DEFAULT_SETTINGS.get("penalty_lecturer_overload_base", 50) * multiplier_lect
        processed_data["settings"]["penalty_lecturer_underload"] = \
            DEFAULT_SETTINGS.get("penalty_lecturer_underload_base", 30) * multiplier_lect
        processed_data["settings"]["penalty_lecturer_insufficient_break"] = \
            DEFAULT_SETTINGS.get("penalty_lecturer_insufficient_break_base", 40) * multiplier_lect

        classroom_prio = priority_settings.get("classroom_util", "medium")
        multiplier_room = priority_multipliers.get(classroom_prio, 1.0)
        processed_data["settings"]["penalty_classroom_underutilized"] = \
            DEFAULT_SETTINGS.get("penalty_classroom_underutilized_base", 10) * multiplier_room
        processed_data["settings"]["penalty_classroom_slightly_empty"] = \
             DEFAULT_SETTINGS.get("penalty_classroom_slightly_empty_base", 2) * multiplier_room

    id_counters = {"lecturer": 0, "timeslot": 0, "classroom": 0}
    
    for item in instructors_model_list:
        if not (hasattr(item, 'id') and item.id is not None): continue
        model_str_id = str(item.id) 
        if model_str_id not in processed_data["mappings"]["lecturer_str_id_to_int_map"]:
            mapped_int_id = id_counters["lecturer"]
            processed_data["mappings"]["lecturer_str_id_to_int_map"][model_str_id] = mapped_int_id
            processed_data["mappings"]["lecturer_int_map_to_str_id"][mapped_int_id] = model_str_id
            id_counters["lecturer"] += 1
    print(f"  Mapped {len(processed_data['mappings']['lecturer_str_id_to_int_map'])} unique lecturers.")

    for item in timeslots_model_list:
        if not (hasattr(item, 'id') and item.id is not None): continue
        model_str_id = str(item.id) 
        if model_str_id not in processed_data["mappings"]["timeslot_str_id_to_int_map"]:
            mapped_int_id = id_counters["timeslot"]
            processed_data["mappings"]["timeslot_str_id_to_int_map"][model_str_id] = mapped_int_id
            processed_data["mappings"]["timeslot_int_map_to_str_id"][mapped_int_id] = model_str_id
            id_counters["timeslot"] += 1
    print(f"  Mapped {len(processed_data['mappings']['timeslot_str_id_to_int_map'])} unique timeslots.")

    for item in classrooms_model_list:
        if not (hasattr(item, 'id') and item.id is not None): continue
        model_pk_id = item.id 
        if model_pk_id not in processed_data["mappings"]["classroom_pk_to_int_map"]:
            mapped_int_id = id_counters["classroom"]
            processed_data["mappings"]["classroom_pk_to_int_map"][model_pk_id] = mapped_int_id
            processed_data["mappings"]["classroom_int_map_to_pk"][mapped_int_id] = model_pk_id
            id_counters["classroom"] += 1
    print(f"  Mapped {len(processed_data['mappings']['classroom_pk_to_int_map'])} unique classrooms.")

    for instructor_model in instructors_model_list:
        if not (hasattr(instructor_model, 'id') and instructor_model.id is not None and hasattr(instructor_model, 'name')): continue
        original_model_str_id = str(instructor_model.id)
        mapped_lecturer_int_id = processed_data["mappings"]["lecturer_str_id_to_int_map"].get(original_model_str_id)
        if mapped_lecturer_int_id is None: continue 
        
        unavailable_mapped_ts_int_ids = set()
        if hasattr(instructor_model, 'unavailable_slot_ids') and instructor_model.unavailable_slot_ids:
            for ts_model_str_id in instructor_model.unavailable_slot_ids:
                mapped_ts_id = processed_data["mappings"]["timeslot_str_id_to_int_map"].get(str(ts_model_str_id))
                if mapped_ts_id is not None:
                    unavailable_mapped_ts_int_ids.add(mapped_ts_id)
        
        db_pk_lecturer = None
        try:
            db_pk_lecturer = int(original_model_str_id)
        except ValueError:
            print(f"UTILS Warning: Could not convert instructor model ID '{original_model_str_id}' to int for DB PK. Storing as None.")

        processed_data["lecturers"][mapped_lecturer_int_id] = {
            "name": instructor_model.name,
            "original_model_id_str": original_model_str_id, 
            "original_db_pk": db_pk_lecturer, 
            "unavailable_slot_ids": list(unavailable_mapped_ts_int_ids) 
        }
    print(f"  Processed {len(processed_data['lecturers'])} lecturers into processed_data.")

    for timeslot_model in timeslots_model_list:
        # Now timeslot_model.start_time, .end_time, .session_date are STRINGS
        essential_attrs = ['id', 'day_of_week', 'start_time', 'end_time', 'num_periods', 'session_date']
        if not all(hasattr(timeslot_model, attr) and getattr(timeslot_model, attr) is not None for attr in essential_attrs):
            missing_attrs = [attr for attr in essential_attrs if not (hasattr(timeslot_model, attr) and getattr(timeslot_model, attr) is not None)]
            # print(f"DEBUG UTILS: Skipping timeslot due to missing attrs: {missing_attrs} in {timeslot_model}")
            continue
        original_model_str_id = str(timeslot_model.id)
        mapped_timeslot_int_id = processed_data["mappings"]["timeslot_str_id_to_int_map"].get(original_model_str_id)
        if mapped_timeslot_int_id is None: continue

        db_pk_timeslot = None
        try:
            db_pk_timeslot = int(original_model_str_id)
        except ValueError:
            print(f"UTILS Warning: Could not convert timeslot model ID '{original_model_str_id}' to int for DB PK. Storing as None.")
        
        # *** MODIFICATION HERE ***
        # Since timeslot_model.start_time, .end_time, .session_date are already strings
        # in the correct format (as per new models.py and data_loader.py),
        # we use them directly. No .isoformat() needed.
        processed_data["timeslots"][mapped_timeslot_int_id] = {
            "day_of_week": timeslot_model.day_of_week,
            "start_time": timeslot_model.start_time,    # Already a string 'HH:MM:SS'
            "end_time": timeslot_model.end_time,        # Already a string 'HH:MM:SS'
            "num_periods": timeslot_model.num_periods,
            "session_date": timeslot_model.session_date, # Already a string 'YYYY-MM-DD'
            "original_model_id_str": original_model_str_id,
            "original_db_pk": db_pk_timeslot
        }
    print(f"  Processed {len(processed_data['timeslots'])} timeslots into processed_data.")

    for classroom_model in classrooms_model_list:
        if not (hasattr(classroom_model, 'id') and classroom_model.id is not None and hasattr(classroom_model, 'capacity')): continue
        original_model_pk_id = classroom_model.id 
        mapped_classroom_int_id = processed_data["mappings"]["classroom_pk_to_int_map"].get(original_model_pk_id)
        if mapped_classroom_int_id is None: continue
        entry = {
            "capacity": classroom_model.capacity, 
            "original_db_pk": original_model_pk_id, 
            "room_code": str(classroom_model.room_code) if hasattr(classroom_model, 'room_code') and classroom_model.room_code else f"RoomPK_{original_model_pk_id}"
        }
        if hasattr(classroom_model, 'type') and classroom_model.type:
            entry["type"] = classroom_model.type 
        processed_data["classrooms"][mapped_classroom_int_id] = entry
    print(f"  Processed {len(processed_data['classrooms'])} classrooms into processed_data.")

    for course_model in courses_model_list:
        essential_attrs = ['id', 'name', 'num_students', 'required_periods_per_session', 'assigned_instructor_id']
        if not all(hasattr(course_model, attr) and getattr(course_model, attr) is not None for attr in essential_attrs):
            continue
        original_course_id_str = str(course_model.id) 
        assigned_instructor_model_str_id = str(course_model.assigned_instructor_id)
        mapped_assigned_lecturer_int_id = processed_data["mappings"]["lecturer_str_id_to_int_map"].get(assigned_instructor_model_str_id)
        
        if mapped_assigned_lecturer_int_id is None:
            print(f"UTILS Warning: Course '{original_course_id_str}' has assigned_instructor_id (model_id_str) '{assigned_instructor_model_str_id}' which was not found in mapped lecturers. Skipping this course.")
            continue
        
        processed_data["courses"][original_course_id_str] = {
            "name": course_model.name, 
            "num_students": course_model.num_students, 
            "required_periods_per_session": course_model.required_periods_per_session, 
            "assigned_instructor_mapped_int_id": mapped_assigned_lecturer_int_id,
        }
    print(f"  Processed {len(processed_data['courses'])} courses into processed_data.")

    for student_model in students_model_list:
        if not (hasattr(student_model, 'id') and student_model.id is not None and hasattr(student_model, 'enrolled_course_ids')):
            continue
        student_original_id_str = str(student_model.id)
        if student_model.enrolled_course_ids:
            for course_original_id_str_enrolled in student_model.enrolled_course_ids:
                course_key = str(course_original_id_str_enrolled)
                if course_key in processed_data["courses"]:
                    processed_data["student_enrollments_map"][course_key].add(student_original_id_str)
                    processed_data["students_courses_map"][student_original_id_str].add(course_key)
    print(f"  Processed student enrollments. Unique courses with enrollments: {len(processed_data['student_enrollments_map'])}. Unique students with enrollments: {len(processed_data['students_courses_map'])}.")

    essential_keys = ["courses", "lecturers", "classrooms", "timeslots"]
    all_essential_present = True
    for key in essential_keys:
        if not processed_data[key]:
            print(f"UTILS Preprocessing CRITICAL Warning: Essential data category '{key}' is empty. This may lead to errors in CP/GA modules.")
            all_essential_present = False
    if not all_essential_present:
        print("UTILS Preprocessing CRITICAL Warning: One or more essential data categories are empty. The solver might not produce meaningful results.")

    print("UTILS: Preprocessing finished.")
    return processed_data


if __name__ == "__main__":
    import os

    current_script_dir = os.path.dirname(os.path.abspath(__file__))

    print("\nUTILS.PY TEST (MOCK DATA): Creating mock model objects...")
    # Mock data now uses string for times/dates in TimeSlot, aligning with new models.py
    mock_courses_list = [
        Course(id="CS101", name="Intro CS", num_students=30, required_periods_per_session=2, assigned_instructor_id="101"),
        Course(id="MA201", name="Math II", num_students=25, required_periods_per_session=3, assigned_instructor_id="102"),
        Course(id="PH100", name="Physics", num_students=40, required_periods_per_session=2, assigned_instructor_id="101")
    ]
    mock_instructors_list = [
        Instructor(id="101", name="Prof X", unavailable_slot_ids={"TS003"}), # TS003 should match an ID in mock_timeslots_list
        Instructor(id="102", name="Dr Y", unavailable_slot_ids=set())
    ]
    mock_classrooms_list = [ 
        Classroom(id=1, room_code="R101", capacity=35, type="Lab"), 
        Classroom(id=2, room_code="R102", capacity=30, type="Theory")
    ]
    mock_timeslots_list = [ 
        TimeSlot(id="TS001", day_of_week="Mon", session_date="2024-01-08", start_time="09:00:00", end_time="10:40:00", num_periods=2),
        TimeSlot(id="TS002", day_of_week="Mon", session_date="2024-01-08", start_time="13:00:00", end_time="15:30:00", num_periods=3),
        TimeSlot(id="TS003", day_of_week="Tue", session_date="2024-01-09", start_time="09:00:00", end_time="10:40:00", num_periods=2)
    ]
    mock_students_list = [ 
        Student(id="S001", enrolled_course_ids={"CS101", "PH100"}),
        Student(id="S002", enrolled_course_ids={"MA201", "CS101"}),
    ]

    output_dir_test_utils_mock = os.path.join(current_script_dir, "output_data_utils_mock_test")
    if not os.path.exists(output_dir_test_utils_mock): os.makedirs(output_dir_test_utils_mock)
    
    print("\nUTILS.PY TEST (MOCK DATA): Running preprocess_data_for_cp_and_ga...")
    mock_priority_settings = {
        "student_clash": "high",
        "lecturer_load_break": "medium",
        "classroom_util": "low"
    }
    processed_mock_data = preprocess_data_for_cp_and_ga(
        mock_courses_list, mock_instructors_list, mock_classrooms_list,
        mock_timeslots_list, mock_students_list, 
        semester_id_for_settings=101,
        priority_settings=mock_priority_settings
    )

    if processed_mock_data:
        print("\nUTILS.PY TEST (MOCK DATA): Preprocessed data (sample):")
        # Use json.dumps for pretty printing the settings from processed_mock_data
        print("  Settings:", json.dumps(processed_mock_data.get("settings"), indent=2))
        
        mappings_snippet = {}
        for map_key, map_dict in processed_mock_data.get("mappings", {}).items():
            mappings_snippet[map_key] = dict(list(map_dict.items())[:2]) 
        print("  Mappings (snippet):", mappings_snippet)

        for data_key in ["courses", "lecturers", "classrooms", "timeslots"]:
            items_dict = processed_mock_data.get(data_key, {})
            first_item_key_or_id = next(iter(items_dict.keys()), None)
            if first_item_key_or_id is not None:
                print(f"  {data_key.capitalize()} (first item sample: Key/MappedID='{first_item_key_or_id}'):", items_dict[first_item_key_or_id])
            else:
                print(f"  {data_key.capitalize()}: (empty)")
        
        print(f"  Student Enrollments Map (first 2 keys): {dict(list(processed_mock_data.get('student_enrollments_map', {}).items())[:2])}")
        print(f"  Students Courses Map (first 2 keys): {dict(list(processed_mock_data.get('students_courses_map', {}).items())[:2])}")

        output_file_mock = os.path.join(output_dir_test_utils_mock, "utils_preprocessed_mock_data.json")
        save_output_data_to_json(processed_mock_data, output_file_mock)
    else:
        print("UTILS.PY TEST (MOCK DATA): Preprocessing returned empty or failed.")
    print("-" * 50)

    print("\nUTILS.PY TEST (REAL DATA): Attempting to load REAL DATA from database...")
    if MODELS_IMPORTED_SUCCESSFULLY:
        try:
            from data_loader import load_all_data 
            
            target_semester_id_for_test = 1
            print(f"UTILS.PY TEST (REAL DATA): Loading data for semester_id = {target_semester_id_for_test}")
            
            db_data = load_all_data(semester_id_to_load=target_semester_id_for_test)
            if db_data is None: # load_all_data might return None on connection error
                print("UTILS.PY TEST (REAL DATA): load_all_data returned None. Skipping further processing.")
            else:
                real_courses_list, real_instructors_list, real_classrooms_list, real_timeslots_list, real_students_list = db_data

                if not (real_courses_list and real_instructors_list and real_classrooms_list and real_timeslots_list): 
                    print(f"UTILS.PY TEST (REAL DATA): Failed to load one or more essential data lists for semester {target_semester_id_for_test}.")
                    print(f"  Loaded counts: Courses({len(real_courses_list or [])}), "
                          f"Instructors({len(real_instructors_list or [])}), "
                          f"Classrooms({len(real_classrooms_list or [])}), "
                          f"TimeSlots({len(real_timeslots_list or [])}), "
                          f"Students({len(real_students_list or [])})")
                else:
                    print(f"UTILS.PY TEST (REAL DATA): Loaded from DB: {len(real_courses_list)} Courses, "
                          f"{len(real_instructors_list)} Instructors, {len(real_classrooms_list)} Classrooms, "
                          f"{len(real_timeslots_list)} TimeSlots, {len(real_students_list)} Students.")

                    output_dir_test_utils_real = os.path.join(current_script_dir, "output_data_utils_real_data_test")
                    if not os.path.exists(output_dir_test_utils_real): os.makedirs(output_dir_test_utils_real)
                    
                    print("\nUTILS.PY TEST (REAL DATA): Running preprocess_data_for_cp_and_ga...")
                    real_priority_settings = { 
                        "student_clash": "medium",
                        "lecturer_load_break": "high",
                        "classroom_util": "medium"
                    }
                    processed_real_data = preprocess_data_for_cp_and_ga(
                        real_courses_list, real_instructors_list, real_classrooms_list,
                        real_timeslots_list, real_students_list,
                        semester_id_for_settings=target_semester_id_for_test,
                        priority_settings=real_priority_settings
                    )

                    if processed_real_data and all(processed_real_data.get(k) for k in ["courses", "lecturers", "classrooms", "timeslots"]):
                        print("\nUTILS.PY TEST (REAL DATA): Preprocessed real data successfully.")
                        # Example: Print a snippet of processed timeslots to verify format
                        if "timeslots" in processed_real_data and processed_real_data["timeslots"]:
                            first_ts_key = next(iter(processed_real_data["timeslots"]))
                            print(f"  Sample processed timeslot (key {first_ts_key}): {processed_real_data['timeslots'][first_ts_key]}")
                        
                        output_file_real = os.path.join(output_dir_test_utils_real, f"utils_preprocessed_real_data_sem_{target_semester_id_for_test}.json")
                        save_output_data_to_json(processed_real_data, output_file_real)
                    else:
                        print("UTILS.PY TEST (REAL DATA): Preprocessing returned empty or failed for essential categories.")
                        if processed_real_data:
                             for k_check in ["courses", "lecturers", "classrooms", "timeslots"]:
                                if not processed_real_data.get(k_check):
                                    print(f"  Category '{k_check}' is empty or missing in processed_real_data.")

        except ImportError:
            print(f"UTILS.PY TEST (REAL DATA): Could not import 'data_loader'. Ensure data_loader.py is in the correct path and has no import errors itself. Skipping real data test.")
        except Exception as e_main_real:
            print(f"UTILS.PY TEST (REAL DATA): An error occurred: {e_main_real}")
            traceback.print_exc()
    else:
        print("UTILS.PY TEST (REAL DATA): Skipped due to models.py import failure.")
    print("\nUTILS.PY All tests finished.")